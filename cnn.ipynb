{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0,), (1,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "mnist_train = datasets.MNIST(\"./data\", train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(\n",
    "    mnist_train, batch_size=batch_size, shuffle=True, drop_last=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    mnist_test, batch_size=batch_size, shuffle=True, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import snntorch as snn\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, beta=0.95):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x0, filters=None):\n",
    "        x = self.pool(F.relu(self.conv1(x0)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "        x = x.flatten(1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        return self.fc4(x)\n",
    "\n",
    "        # x = F.softmax(self.fc3(x))\n",
    "\n",
    "        # return x, filter\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "net = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 \t Train Loss: 2.309497117996216\n",
      "Iteration: 1 \t Train Loss: 2.301856279373169\n",
      "Iteration: 2 \t Train Loss: 2.293412923812866\n",
      "Iteration: 3 \t Train Loss: 2.290461301803589\n",
      "Iteration: 4 \t Train Loss: 2.2786757946014404\n",
      "Iteration: 5 \t Train Loss: 2.2800419330596924\n",
      "Iteration: 6 \t Train Loss: 2.2743091583251953\n",
      "Iteration: 7 \t Train Loss: 2.2552077770233154\n",
      "Iteration: 8 \t Train Loss: 2.256417989730835\n",
      "Iteration: 9 \t Train Loss: 2.234023332595825\n",
      "Iteration: 10 \t Train Loss: 2.2234766483306885\n",
      "Iteration: 11 \t Train Loss: 2.2056729793548584\n",
      "Iteration: 12 \t Train Loss: 2.1975064277648926\n",
      "Iteration: 13 \t Train Loss: 2.1773080825805664\n",
      "Iteration: 14 \t Train Loss: 2.147063970565796\n",
      "Iteration: 15 \t Train Loss: 2.140937089920044\n",
      "Iteration: 16 \t Train Loss: 2.108513116836548\n",
      "Iteration: 17 \t Train Loss: 2.0639944076538086\n",
      "Iteration: 18 \t Train Loss: 2.049619436264038\n",
      "Iteration: 19 \t Train Loss: 2.02984881401062\n",
      "Iteration: 20 \t Train Loss: 2.0038208961486816\n",
      "Iteration: 21 \t Train Loss: 1.9520796537399292\n",
      "Iteration: 22 \t Train Loss: 1.9321672916412354\n",
      "Iteration: 23 \t Train Loss: 1.8738261461257935\n",
      "Iteration: 24 \t Train Loss: 1.8317537307739258\n",
      "Iteration: 25 \t Train Loss: 1.812066674232483\n",
      "Iteration: 26 \t Train Loss: 1.7235037088394165\n",
      "Iteration: 27 \t Train Loss: 1.6922768354415894\n",
      "Iteration: 28 \t Train Loss: 1.6477347612380981\n",
      "Iteration: 29 \t Train Loss: 1.6092665195465088\n",
      "Iteration: 30 \t Train Loss: 1.564727783203125\n",
      "Iteration: 31 \t Train Loss: 1.5077793598175049\n",
      "Iteration: 32 \t Train Loss: 1.4375628232955933\n",
      "Iteration: 33 \t Train Loss: 1.4111436605453491\n",
      "Iteration: 34 \t Train Loss: 1.3615463972091675\n",
      "Iteration: 35 \t Train Loss: 1.244141936302185\n",
      "Iteration: 36 \t Train Loss: 1.2997747659683228\n",
      "Iteration: 37 \t Train Loss: 1.1912585496902466\n",
      "Iteration: 38 \t Train Loss: 1.0952998399734497\n",
      "Iteration: 39 \t Train Loss: 1.0164304971694946\n",
      "Iteration: 40 \t Train Loss: 1.2117564678192139\n",
      "Iteration: 41 \t Train Loss: 0.9186338782310486\n",
      "Iteration: 42 \t Train Loss: 0.9084069132804871\n",
      "Iteration: 43 \t Train Loss: 0.8599944710731506\n",
      "Iteration: 44 \t Train Loss: 0.9204397201538086\n",
      "Iteration: 45 \t Train Loss: 0.9127766489982605\n",
      "Iteration: 46 \t Train Loss: 0.9630926847457886\n",
      "Iteration: 47 \t Train Loss: 0.830479085445404\n",
      "Iteration: 48 \t Train Loss: 0.7548595666885376\n",
      "Iteration: 49 \t Train Loss: 0.9622460007667542\n",
      "Iteration: 50 \t Train Loss: 0.7750024199485779\n",
      "Iteration: 51 \t Train Loss: 0.7544530034065247\n",
      "Iteration: 52 \t Train Loss: 0.5577449798583984\n",
      "Iteration: 53 \t Train Loss: 0.7310582399368286\n",
      "Iteration: 54 \t Train Loss: 0.7034936547279358\n",
      "Iteration: 55 \t Train Loss: 0.8858001828193665\n",
      "Iteration: 56 \t Train Loss: 0.7106465101242065\n",
      "Iteration: 57 \t Train Loss: 0.6748099327087402\n",
      "Iteration: 58 \t Train Loss: 0.6440974473953247\n",
      "Iteration: 59 \t Train Loss: 0.5802167654037476\n",
      "Iteration: 60 \t Train Loss: 0.6810824871063232\n",
      "Iteration: 61 \t Train Loss: 0.734702467918396\n",
      "Iteration: 62 \t Train Loss: 0.7315179109573364\n",
      "Iteration: 63 \t Train Loss: 0.5962962508201599\n",
      "Iteration: 64 \t Train Loss: 0.5210485458374023\n",
      "Iteration: 65 \t Train Loss: 0.49291354417800903\n",
      "Iteration: 66 \t Train Loss: 0.6401354670524597\n",
      "Iteration: 67 \t Train Loss: 0.5330895185470581\n",
      "Iteration: 68 \t Train Loss: 0.5912046432495117\n",
      "Iteration: 69 \t Train Loss: 0.4825417995452881\n",
      "Iteration: 70 \t Train Loss: 0.4698134958744049\n",
      "Iteration: 71 \t Train Loss: 0.6413524746894836\n",
      "Iteration: 72 \t Train Loss: 0.41676342487335205\n",
      "Iteration: 73 \t Train Loss: 0.46104976534843445\n",
      "Iteration: 74 \t Train Loss: 0.6197890043258667\n",
      "Iteration: 75 \t Train Loss: 0.6786177158355713\n",
      "Iteration: 76 \t Train Loss: 0.4965551495552063\n",
      "Iteration: 77 \t Train Loss: 0.4280373156070709\n",
      "Iteration: 78 \t Train Loss: 0.5869007110595703\n",
      "Iteration: 79 \t Train Loss: 0.5004321336746216\n",
      "Iteration: 80 \t Train Loss: 0.4183938801288605\n",
      "Iteration: 81 \t Train Loss: 0.39684969186782837\n",
      "Iteration: 82 \t Train Loss: 0.3958958089351654\n",
      "Iteration: 83 \t Train Loss: 0.4610663652420044\n",
      "Iteration: 84 \t Train Loss: 0.4647572636604309\n",
      "Iteration: 85 \t Train Loss: 0.34840360283851624\n",
      "Iteration: 86 \t Train Loss: 0.48994988203048706\n",
      "Iteration: 87 \t Train Loss: 0.33701473474502563\n",
      "Iteration: 88 \t Train Loss: 0.37747377157211304\n",
      "Iteration: 89 \t Train Loss: 0.4459715485572815\n",
      "Iteration: 90 \t Train Loss: 0.47165757417678833\n",
      "Iteration: 91 \t Train Loss: 0.3858141005039215\n",
      "Iteration: 92 \t Train Loss: 0.37351369857788086\n",
      "Iteration: 93 \t Train Loss: 0.8074601888656616\n",
      "Iteration: 94 \t Train Loss: 0.523482084274292\n",
      "Iteration: 95 \t Train Loss: 0.5360803008079529\n",
      "Iteration: 96 \t Train Loss: 0.605865478515625\n",
      "Iteration: 97 \t Train Loss: 0.5576614737510681\n",
      "Iteration: 98 \t Train Loss: 0.3625577986240387\n",
      "Iteration: 99 \t Train Loss: 0.4259095788002014\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=5e-4)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(1):\n",
    "    train_batch = iter(train_loader)\n",
    "\n",
    "    for data, targets in train_batch:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        net.train()\n",
    "        result = net(data)\n",
    "\n",
    "        loss_val = torch.zeros((1), device=device)\n",
    "        loss_val = loss(result, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print train/test loss/accuracy\n",
    "        # if counter % 10 == 0:\n",
    "        print(f\"Iteration: {counter} \\t Train Loss: {loss_val.item()}\")\n",
    "        counter += 1\n",
    "\n",
    "        if counter == 100:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 8\n",
      "Iteration: 9\n",
      "Iteration: 10\n",
      "Iteration: 11\n",
      "Iteration: 12\n",
      "Iteration: 13\n",
      "Iteration: 14\n",
      "Iteration: 15\n",
      "Iteration: 16\n",
      "Iteration: 17\n",
      "Iteration: 18\n",
      "Iteration: 19\n",
      "Iteration: 20\n",
      "Iteration: 21\n",
      "Iteration: 22\n",
      "Iteration: 23\n",
      "Iteration: 24\n",
      "Iteration: 25\n",
      "Iteration: 26\n",
      "Iteration: 27\n",
      "Iteration: 28\n",
      "Iteration: 29\n",
      "Iteration: 30\n",
      "Iteration: 31\n",
      "Iteration: 32\n",
      "Iteration: 33\n",
      "Iteration: 34\n",
      "Iteration: 35\n",
      "Iteration: 36\n",
      "Iteration: 37\n",
      "Iteration: 38\n",
      "Iteration: 39\n",
      "Iteration: 40\n",
      "Iteration: 41\n",
      "Iteration: 42\n",
      "Iteration: 43\n",
      "Iteration: 44\n",
      "Iteration: 45\n",
      "Iteration: 46\n",
      "Iteration: 47\n",
      "Iteration: 48\n",
      "Iteration: 49\n",
      "Iteration: 50\n",
      "Iteration: 51\n",
      "Iteration: 52\n",
      "Iteration: 53\n",
      "Iteration: 54\n",
      "Iteration: 55\n",
      "Iteration: 56\n",
      "Iteration: 57\n",
      "Iteration: 58\n",
      "Iteration: 59\n",
      "Iteration: 60\n",
      "Iteration: 61\n",
      "Iteration: 62\n",
      "Iteration: 63\n",
      "Iteration: 64\n",
      "Iteration: 65\n",
      "Iteration: 66\n",
      "Iteration: 67\n",
      "Iteration: 68\n",
      "Iteration: 69\n",
      "Iteration: 70\n",
      "Iteration: 71\n",
      "Iteration: 72\n",
      "Iteration: 73\n",
      "Iteration: 74\n",
      "Iteration: 75\n",
      "Iteration: 76\n",
      "Iteration: 77\n",
      "Test Accuracy: 88.08%\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "counter = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, targets in test_loader:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        outputs = net(data)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        print(f\"Iteration: {counter}\")\n",
    "        counter += 1\n",
    "        if counter == 100:\n",
    "            break\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
