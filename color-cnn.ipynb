{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0,), (1,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "mnist_train = datasets.CIFAR10(\"./data\", train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.CIFAR10(\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(\n",
    "    mnist_train, batch_size=batch_size, shuffle=True, drop_last=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    mnist_test, batch_size=batch_size, shuffle=True, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import snntorch as snn\n",
    "\n",
    "\n",
    "class CNNDenseSNN(nn.Module):\n",
    "    def __init__(self, beta=0.9):\n",
    "        super(CNNDenseSNN, self).__init__()\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "        self.lif1 = snn.Leaky(beta=beta)\n",
    "\n",
    "    def forward(self, x0, filters=None):\n",
    "        x = self.pool(F.relu(self.conv1(x0)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "        x = x.flatten(1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        return self.fc4(x)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "net = CNNDenseSNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 \t Train Loss: 2.3061420917510986\n",
      "Iteration: 1 \t Train Loss: 2.299863338470459\n",
      "Iteration: 2 \t Train Loss: 2.2932024002075195\n",
      "Iteration: 3 \t Train Loss: 2.3027353286743164\n",
      "Iteration: 4 \t Train Loss: 2.303922176361084\n",
      "Iteration: 5 \t Train Loss: 2.2963435649871826\n",
      "Iteration: 6 \t Train Loss: 2.297429323196411\n",
      "Iteration: 7 \t Train Loss: 2.294356346130371\n",
      "Iteration: 8 \t Train Loss: 2.293600082397461\n",
      "Iteration: 9 \t Train Loss: 2.3017053604125977\n",
      "Iteration: 10 \t Train Loss: 2.291574239730835\n",
      "Iteration: 11 \t Train Loss: 2.2909469604492188\n",
      "Iteration: 12 \t Train Loss: 2.2822811603546143\n",
      "Iteration: 13 \t Train Loss: 2.291254758834839\n",
      "Iteration: 14 \t Train Loss: 2.2719624042510986\n",
      "Iteration: 15 \t Train Loss: 2.265568256378174\n",
      "Iteration: 16 \t Train Loss: 2.2657246589660645\n",
      "Iteration: 17 \t Train Loss: 2.2598495483398438\n",
      "Iteration: 18 \t Train Loss: 2.2499544620513916\n",
      "Iteration: 19 \t Train Loss: 2.219468593597412\n",
      "Iteration: 20 \t Train Loss: 2.2082362174987793\n",
      "Iteration: 21 \t Train Loss: 2.2622106075286865\n",
      "Iteration: 22 \t Train Loss: 2.240910768508911\n",
      "Iteration: 23 \t Train Loss: 2.2074968814849854\n",
      "Iteration: 24 \t Train Loss: 2.2024495601654053\n",
      "Iteration: 25 \t Train Loss: 2.2028493881225586\n",
      "Iteration: 26 \t Train Loss: 2.1979806423187256\n",
      "Iteration: 27 \t Train Loss: 2.1701772212982178\n",
      "Iteration: 28 \t Train Loss: 2.1624040603637695\n",
      "Iteration: 29 \t Train Loss: 2.1427481174468994\n",
      "Iteration: 30 \t Train Loss: 2.1017322540283203\n",
      "Iteration: 31 \t Train Loss: 2.0963802337646484\n",
      "Iteration: 32 \t Train Loss: 2.0639452934265137\n",
      "Iteration: 33 \t Train Loss: 2.1965136528015137\n",
      "Iteration: 34 \t Train Loss: 2.133476734161377\n",
      "Iteration: 35 \t Train Loss: 2.044799327850342\n",
      "Iteration: 36 \t Train Loss: 2.1276698112487793\n",
      "Iteration: 37 \t Train Loss: 1.989585518836975\n",
      "Iteration: 38 \t Train Loss: 2.138941764831543\n",
      "Iteration: 39 \t Train Loss: 2.012573480606079\n",
      "Iteration: 40 \t Train Loss: 2.102820873260498\n",
      "Iteration: 41 \t Train Loss: 2.0430445671081543\n",
      "Iteration: 42 \t Train Loss: 2.048114776611328\n",
      "Iteration: 43 \t Train Loss: 2.084760904312134\n",
      "Iteration: 44 \t Train Loss: 1.9860395193099976\n",
      "Iteration: 45 \t Train Loss: 2.0227808952331543\n",
      "Iteration: 46 \t Train Loss: 2.06310772895813\n",
      "Iteration: 47 \t Train Loss: 2.048123836517334\n",
      "Iteration: 48 \t Train Loss: 1.9131057262420654\n",
      "Iteration: 49 \t Train Loss: 2.0431830883026123\n",
      "Iteration: 50 \t Train Loss: 1.991494059562683\n",
      "Iteration: 51 \t Train Loss: 1.923696517944336\n",
      "Iteration: 52 \t Train Loss: 1.9914482831954956\n",
      "Iteration: 53 \t Train Loss: 2.0183982849121094\n",
      "Iteration: 54 \t Train Loss: 1.9948451519012451\n",
      "Iteration: 55 \t Train Loss: 2.0727412700653076\n",
      "Iteration: 56 \t Train Loss: 1.9269428253173828\n",
      "Iteration: 57 \t Train Loss: 2.0283915996551514\n",
      "Iteration: 58 \t Train Loss: 1.9425257444381714\n",
      "Iteration: 59 \t Train Loss: 2.0481057167053223\n",
      "Iteration: 60 \t Train Loss: 2.001246452331543\n",
      "Iteration: 61 \t Train Loss: 1.9601656198501587\n",
      "Iteration: 62 \t Train Loss: 2.0251784324645996\n",
      "Iteration: 63 \t Train Loss: 2.0117969512939453\n",
      "Iteration: 64 \t Train Loss: 1.9000834226608276\n",
      "Iteration: 65 \t Train Loss: 1.9953120946884155\n",
      "Iteration: 66 \t Train Loss: 1.990446925163269\n",
      "Iteration: 67 \t Train Loss: 1.8902478218078613\n",
      "Iteration: 68 \t Train Loss: 1.9024264812469482\n",
      "Iteration: 69 \t Train Loss: 1.9755510091781616\n",
      "Iteration: 70 \t Train Loss: 2.0564091205596924\n",
      "Iteration: 71 \t Train Loss: 1.9900708198547363\n",
      "Iteration: 72 \t Train Loss: 1.825674295425415\n",
      "Iteration: 73 \t Train Loss: 1.8724462985992432\n",
      "Iteration: 74 \t Train Loss: 1.841623306274414\n",
      "Iteration: 75 \t Train Loss: 1.9181193113327026\n",
      "Iteration: 76 \t Train Loss: 1.8700711727142334\n",
      "Iteration: 77 \t Train Loss: 1.8762104511260986\n",
      "Iteration: 78 \t Train Loss: 1.7881150245666504\n",
      "Iteration: 79 \t Train Loss: 1.8418364524841309\n",
      "Iteration: 80 \t Train Loss: 1.895477294921875\n",
      "Iteration: 81 \t Train Loss: 2.004122257232666\n",
      "Iteration: 82 \t Train Loss: 1.996341586112976\n",
      "Iteration: 83 \t Train Loss: 1.9280184507369995\n",
      "Iteration: 84 \t Train Loss: 2.0534629821777344\n",
      "Iteration: 85 \t Train Loss: 1.915709376335144\n",
      "Iteration: 86 \t Train Loss: 1.8826704025268555\n",
      "Iteration: 87 \t Train Loss: 1.8263270854949951\n",
      "Iteration: 88 \t Train Loss: 1.9072775840759277\n",
      "Iteration: 89 \t Train Loss: 1.756641149520874\n",
      "Iteration: 90 \t Train Loss: 1.9851319789886475\n",
      "Iteration: 91 \t Train Loss: 1.9504884481430054\n",
      "Iteration: 92 \t Train Loss: 1.900449514389038\n",
      "Iteration: 93 \t Train Loss: 1.7736269235610962\n",
      "Iteration: 94 \t Train Loss: 1.7379631996154785\n",
      "Iteration: 95 \t Train Loss: 1.8776072263717651\n",
      "Iteration: 96 \t Train Loss: 1.8004604578018188\n",
      "Iteration: 97 \t Train Loss: 1.8588624000549316\n",
      "Iteration: 98 \t Train Loss: 1.7924644947052002\n",
      "Iteration: 99 \t Train Loss: 1.859395146369934\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=5e-4)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(1):\n",
    "    train_batch = iter(train_loader)\n",
    "\n",
    "    for data, targets in train_batch:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        net.train()\n",
    "        result = net(data)\n",
    "\n",
    "        loss_val = torch.zeros((1), device=device)\n",
    "        loss_val = loss(result, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print train/test loss/accuracy\n",
    "        # if counter % 10 == 0:\n",
    "        print(f\"Iteration: {counter} \\t Train Loss: {loss_val.item()}\")\n",
    "        counter += 1\n",
    "\n",
    "        if counter == 100:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 8\n",
      "Iteration: 9\n",
      "Iteration: 10\n",
      "Iteration: 11\n",
      "Iteration: 12\n",
      "Iteration: 13\n",
      "Iteration: 14\n",
      "Iteration: 15\n",
      "Iteration: 16\n",
      "Iteration: 17\n",
      "Iteration: 18\n",
      "Iteration: 19\n",
      "Iteration: 20\n",
      "Iteration: 21\n",
      "Iteration: 22\n",
      "Iteration: 23\n",
      "Iteration: 24\n",
      "Iteration: 25\n",
      "Iteration: 26\n",
      "Iteration: 27\n",
      "Iteration: 28\n",
      "Iteration: 29\n",
      "Iteration: 30\n",
      "Iteration: 31\n",
      "Iteration: 32\n",
      "Iteration: 33\n",
      "Iteration: 34\n",
      "Iteration: 35\n",
      "Iteration: 36\n",
      "Iteration: 37\n",
      "Iteration: 38\n",
      "Iteration: 39\n",
      "Iteration: 40\n",
      "Iteration: 41\n",
      "Iteration: 42\n",
      "Iteration: 43\n",
      "Iteration: 44\n",
      "Iteration: 45\n",
      "Iteration: 46\n",
      "Iteration: 47\n",
      "Iteration: 48\n",
      "Iteration: 49\n",
      "Iteration: 50\n",
      "Iteration: 51\n",
      "Iteration: 52\n",
      "Iteration: 53\n",
      "Iteration: 54\n",
      "Iteration: 55\n",
      "Iteration: 56\n",
      "Iteration: 57\n",
      "Iteration: 58\n",
      "Iteration: 59\n",
      "Iteration: 60\n",
      "Iteration: 61\n",
      "Iteration: 62\n",
      "Iteration: 63\n",
      "Iteration: 64\n",
      "Iteration: 65\n",
      "Iteration: 66\n",
      "Iteration: 67\n",
      "Iteration: 68\n",
      "Iteration: 69\n",
      "Iteration: 70\n",
      "Iteration: 71\n",
      "Iteration: 72\n",
      "Iteration: 73\n",
      "Iteration: 74\n",
      "Iteration: 75\n",
      "Iteration: 76\n",
      "Iteration: 77\n",
      "Test Accuracy: 31.03%\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "counter = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, targets in test_loader:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        outputs = net(data)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        print(f\"Iteration: {counter}\")\n",
    "        counter += 1\n",
    "        if counter == 100:\n",
    "            break\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
